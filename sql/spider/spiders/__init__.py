# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.
# import requests
# headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}
# r = requests.get('https://s.taobao.com/search?q=phone&js=1&stats_click=search_radio_all%3A1&initiative_id=staobaoz_20210621&ie=utf8&bcoffset=-5&p4ppushleft=2%2C48&s=176&ntoffset=-5', headers = headers)
# a = ''
# for cookie in r.cookies:
#
#     a += cookie.name+'='+cookie.value+';'
#     print(cookie.name)
#     print(cookie.value)
#     print("=========")
# print(a)